{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import (svm, preprocessing)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (recall_score, precision_score, accuracy_score, confusion_matrix,)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"Accident_train.csv\")\n",
    "data_test = pd.read_csv(\"Accident_test.csv\")\n",
    "#data_train.head()\n",
    "#data_test.head()\n",
    "#data_train.info()\n",
    "#data_test.info()\n",
    "#data_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    8529\n",
       "3.0      26\n",
       "2.0      18\n",
       "Name: Ped_Crossing_HC, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_train[\"Weekday_of_Collision\"].value_counts()\n",
    "#data_train[\"Policing_Area\"].value_counts()\n",
    "#data_test[\"Policing_Area\"].value_counts()\n",
    "#data_test[\"Collision_Severity\"].value_counts()\n",
    "#data_test[\"Weekday_of_Collision\"].value_counts()\n",
    "data_train[\"Ped_Crossing_HC\"].value_counts()\n",
    "#print(type(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# lable encoder for data_train\n",
    "le.fit(data_train['Weekday_of_Collision'])\n",
    "data_train['Weekday_of_Collision'] = le.transform(data_train['Weekday_of_Collision'])\n",
    "le.fit(data_train['Policing_Area'].astype(str))\n",
    "data_train['Policing_Area'] = le.transform(data_train['Policing_Area'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Nan Values to mean/mode etc.,\n",
    "#data_train.isna().any()\n",
    "#data_train.mean()\n",
    "#data_train.isna().any()\n",
    "data_train = data_train.fillna(data_train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lable encoder for data_test\n",
    "le.fit(data_test['Collision_Severity'])\n",
    "data_test['Collision_Severity'] = le.transform(data_test['Collision_Severity'])\n",
    "le.fit(data_test['Weekday_of_Collision'])\n",
    "data_test['Weekday_of_Collision'] = le.transform(data_test['Weekday_of_Collision'])\n",
    "le.fit(data_test['Policing_Area'].astype(str))\n",
    "data_test['Policing_Area'] = le.transform(data_test['Policing_Area'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8849 entries, 0 to 8848\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Collision_Ref_No            8849 non-null   int64  \n",
      " 1   Policing_Area               8849 non-null   int32  \n",
      " 2   Collision_Severity          8849 non-null   int64  \n",
      " 3   Weekday_of_Collision        8849 non-null   int32  \n",
      " 4   Day_of_Collision            8849 non-null   int64  \n",
      " 5   Month_of_Collision          8849 non-null   int64  \n",
      " 6   Hour_of_Collision           8849 non-null   float64\n",
      " 7   Carriageway_Type            8849 non-null   int64  \n",
      " 8   Speed_Limit                 8849 non-null   int64  \n",
      " 9   Junction_Detail             8849 non-null   float64\n",
      " 10  Junction_Control            8849 non-null   float64\n",
      " 11  Ped_Crossing_HC             8849 non-null   float64\n",
      " 12  Ped_Crossing_PC             8849 non-null   float64\n",
      " 13  Light_Conditions            8849 non-null   int64  \n",
      " 14  Weather_Conditions          8849 non-null   int64  \n",
      " 15  Road_Surface_Conditions     8849 non-null   float64\n",
      " 16  Special_Conditions_at_Site  8849 non-null   float64\n",
      "dtypes: float64(7), int32(2), int64(8)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Nan Values to mean/mode etc.,\n",
    "#data_test.isna().any()\n",
    "#data_test.mean()\n",
    "data_test = data_test.fillna(data_test.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collision_Ref_No</th>\n",
       "      <th>Policing_Area</th>\n",
       "      <th>Collision_Severity</th>\n",
       "      <th>Weekday_of_Collision</th>\n",
       "      <th>Day_of_Collision</th>\n",
       "      <th>Month_of_Collision</th>\n",
       "      <th>Hour_of_Collision</th>\n",
       "      <th>Carriageway_Type</th>\n",
       "      <th>Speed_Limit</th>\n",
       "      <th>Junction_Detail</th>\n",
       "      <th>Junction_Control</th>\n",
       "      <th>Ped_Crossing_HC</th>\n",
       "      <th>Ped_Crossing_PC</th>\n",
       "      <th>Light_Conditions</th>\n",
       "      <th>Weather_Conditions</th>\n",
       "      <th>Road_Surface_Conditions</th>\n",
       "      <th>Special_Conditions_at_Site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3518</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10557</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5002</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11714</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12416</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Collision_Ref_No  Policing_Area  Collision_Severity  Weekday_of_Collision  \\\n",
       "0              3518             19                   3                     1   \n",
       "1             10557              7                   3                     2   \n",
       "2              5002             28                   3                     6   \n",
       "3             11714              7                   3                     3   \n",
       "4             12416             32                   3                     1   \n",
       "\n",
       "   Day_of_Collision  Month_of_Collision  Hour_of_Collision  Carriageway_Type  \\\n",
       "0                 4                   8               14.0                13   \n",
       "1                 8                   8               17.0                11   \n",
       "2                 5                  11               17.0                 1   \n",
       "3                18                  10               16.0                12   \n",
       "4                23                  11                9.0                13   \n",
       "\n",
       "   Speed_Limit  Junction_Detail  Junction_Control  Ped_Crossing_HC  \\\n",
       "0           60              1.0               1.0              1.0   \n",
       "1           50             12.0               7.0              1.0   \n",
       "2           60             12.0               7.0              1.0   \n",
       "3           70              6.0               4.0              1.0   \n",
       "4           60              6.0               7.0              1.0   \n",
       "\n",
       "   Ped_Crossing_PC  Light_Conditions  Weather_Conditions  \\\n",
       "0              1.0                 2                   9   \n",
       "1              1.0                 4                   3   \n",
       "2              1.0                 2                   2   \n",
       "3              1.0                 1                   3   \n",
       "4              1.0                 2                   3   \n",
       "\n",
       "   Road_Surface_Conditions  Special_Conditions_at_Site  \n",
       "0                      9.0                         1.0  \n",
       "1                      1.0                         1.0  \n",
       "2                      2.0                         1.0  \n",
       "3                      1.0                         1.0  \n",
       "4                      1.0                         1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = data_train[\"Collision_Severity\"]\n",
    "data_train_x = data_train.drop([\"Collision_Severity\", \"Collision_Ref_No\"], axis=1)\n",
    "\n",
    "data_test_x = data_test.drop([\"Collision_Severity\", \"Collision_Ref_No\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8849, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# splitting test vales into parts to find get lables\n",
    "data_variables = train_test_split(data_train_x, labels_train, test_size = 0.25, random_state = 42)\n",
    "#data_variables = train_test_split(data_train, labels_train, test_size=0.33, random_state=99)\n",
    "data_train_l, data_test_l, labels_train_l, labels_test_l = data_variables\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(data_train_l)\n",
    "train_data_scaled = scaler.transform(data_train_l)\n",
    "test_data_scaled = scaler.transform(data_test_l)\n",
    "\n",
    "test_data_scaled_x = scaler.transform(data_test_x)\n",
    "\n",
    "#pca = PCA(n_components = 14)\n",
    "#train_data_scaled = pca.fit_transform(data_train_l)\n",
    "#test_data_scaled = pca.transform(data_test_l)\n",
    "#explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "#test_data_scaled_x = pca.transform(data_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 2183, 2: 30})\n",
      "accuracy  : 0.8992318120198826\n",
      "accuracy[round]  : 0.899\n",
      "precision : 0.8992318120198826\n",
      "recall    : 0.8992318120198826 \n",
      "\n",
      "Confusion matrix \n",
      "[[   0    4   23]\n",
      " [   0   18  188]\n",
      " [   0    8 1972]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(train_data_scaled, labels_train_l)\n",
    "\n",
    "classifier.fit(train_data_scaled, labels_train_l)\n",
    "\n",
    "# Predicting test data with train data using classifier\n",
    "predict_y = classifier.predict(test_data_scaled)\n",
    "\n",
    "#print(type(predict_y))\n",
    "a = np.array(predict_y)\n",
    "print(collections.Counter(a))\n",
    "#for x in predict_y:\n",
    "#  print(x)\n",
    "\n",
    "accuracy = classifier.score(test_data_scaled, labels_test_l)\n",
    "\n",
    "precision = precision_score(labels_test_l, predict_y, average='micro')\n",
    "recall = recall_score(labels_test_l, predict_y, average='micro')\n",
    "\n",
    "cmatrix = confusion_matrix(labels_test_l, predict_y)\n",
    "print(\"accuracy  : {}\".format(accuracy))\n",
    "print(\"accuracy[round]  : {}\".format(round(accuracy, 3)))\n",
    "print(\"precision : {}\".format(precision))\n",
    "print(\"recall    : {} \\n\".format(recall))\n",
    "print(\"Confusion matrix \\n{}\\n\\n\".format(cmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saibhargav\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>89.79</td>\n",
       "      <td>{3: 2185, 2: 28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>89.47</td>\n",
       "      <td>{3: 2213}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>89.47</td>\n",
       "      <td>{3: 2213}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>89.47</td>\n",
       "      <td>{3: 2213}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>89.47</td>\n",
       "      <td>{3: 2213}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>86.99</td>\n",
       "      <td>{3: 2105, 2: 84, 1: 24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>85.31</td>\n",
       "      <td>{3: 1958, 2: 215, 1: 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>83.01</td>\n",
       "      <td>{3: 1992, 2: 192, 1: 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>9.81</td>\n",
       "      <td>{1: 1982, 3: 193, 2: 38}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Score                     Count\n",
       "3               Random Forest  89.79          {3: 2185, 2: 28}\n",
       "0     Support Vector Machines  89.47                 {3: 2213}\n",
       "2         Logistic Regression  89.47                 {3: 2213}\n",
       "6  Stochastic Gradient Decent  89.47                 {3: 2213}\n",
       "7                  Linear SVC  89.47                 {3: 2213}\n",
       "1                         KNN  86.99   {3: 2105, 2: 84, 1: 24}\n",
       "8               Decision Tree  85.31  {3: 1958, 2: 215, 1: 40}\n",
       "5                  Perceptron  83.01  {3: 1992, 2: 192, 1: 29}\n",
       "4                 Naive Bayes   9.81  {1: 1982, 3: 193, 2: 38}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVC\n",
    "svc = SVC()\n",
    "svc.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = svc.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_svc = collections.Counter(a)\n",
    "acc_svc = round(svc.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_svc\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = knn.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_knn = collections.Counter(a)\n",
    "acc_knn = round(knn.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_knn\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = logreg.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_log = collections.Counter(a)\n",
    "acc_log = round(logreg.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_log\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = gaussian.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_gaussian = collections.Counter(a)\n",
    "acc_gaussian = round(gaussian.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_gaussian\n",
    "\n",
    "# Perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = perceptron.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_perceptron = collections.Counter(a)\n",
    "acc_perceptron = round(perceptron.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_perceptron\n",
    "\n",
    "# Linear SVC\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = linear_svc.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_linear_svc = collections.Counter(a)\n",
    "acc_linear_svc = round(linear_svc.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_linear_svc\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = sgd.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_sgd = collections.Counter(a)\n",
    "acc_sgd = round(sgd.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_sgd\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = decision_tree.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_decision_tree = collections.Counter(a)\n",
    "acc_decision_tree = round(decision_tree.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_decision_tree\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(train_data_scaled, labels_train_l)\n",
    "Y_pred = random_forest.predict(test_data_scaled)\n",
    "a = np.array(Y_pred)\n",
    "predict_random_forest = collections.Counter(a)\n",
    "acc_random_forest = round(random_forest.score(test_data_scaled, labels_test_l) * 100, 2)\n",
    "acc_random_forest\n",
    "\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree],\n",
    "    'Count': [predict_svc, predict_knn, predict_log, \n",
    "              predict_random_forest, predict_gaussian, predict_perceptron, \n",
    "              predict_sgd, predict_linear_svc, predict_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
